Seeing The Unseen

An AI Assistant for the Visually Impaired

ğŸ“Œ Overview

Seeing The Unseen is an AI-powered assistive system designed to help visually impaired users better understand their surroundings through real-time audio feedback.
The system combines computer vision, speech processing, and intelligent automation to detect objects, read text, recognize currency, identify people, and describe scenes â€” all through a mobile application connected to smart glasses.

The goal is to increase independence, safety, and confidence by transforming visual information into meaningful audio insights.

ğŸ¯ Key Features

Object Detection â€“ Identifies surrounding objects and announces them via voice output

Text Reading (OCR) â€“ Reads printed text such as signs, documents, and labels

Currency Recognition â€“ Detects and announces currency denominations

Person Identification â€“ Identifies known individuals (where permitted)

Scene Description â€“ Provides intelligent descriptions of the userâ€™s environment

Real-Time Audio Feedback â€“ Instant voice responses for seamless interaction

Offline Capability â€“ Core functionalities work without internet access

ğŸ§  System Architecture

Mobile Application

Handles all AI processing and decision-making

Supports voice and touch-based commands

Performs detection using on-device models

Smart Glasses

Acts as an input/output interface

Sends user commands to the mobile app

Delivers audio feedback to the user

Does not perform any AI processing independently

Connectivity

Smart glasses connect to the mobile app via Bluetooth or Wi-Fi

Automatic fallback to mobile-only mode if glasses are disconnected

ğŸ› ï¸ Technologies Used

Programming Languages: Python, Dart

Mobile Framework: Flutter

AI / ML: Computer Vision models, OCR, Object Detection

Audio Processing: Speech-to-text and text-to-speech pipelines

Tools: Google Colab, VS Code, Android Studio

ğŸ” User Interaction & Flow

Biometric Authentication

Secure login before accessing system features

Mode Selection

Object Detection

OCR

Currency Recognition

Person Identification

Command Input

Either voice or touch input (one at a time)

Processing & Feedback

AI models analyze input

Audio output is delivered to the user in real time

ğŸš€ Project Objectives

Reduce dependency on external assistance

Provide accurate and fast environmental awareness

Enable accessible, hands-free interaction

Design a scalable system for future AI enhancements
